{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import string\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.snowball import *\n",
    "from datasets import list_metrics, load_metric\n",
    "from collections import Counter\n",
    "from transformers import GPT2Tokenizer, GPT2TokenizerFast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue</th>\n",
       "      <th>Actual_Solution</th>\n",
       "      <th>Pred_Solution</th>\n",
       "      <th>Response_PPL</th>\n",
       "      <th>Total_PPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mrh aft scissors has side to side play        ...</td>\n",
       "      <td>removed, inspected, and reshimmed aft scissor...</td>\n",
       "      <td>inspected mrh aft scissor iaw 150-300. play is...</td>\n",
       "      <td>1.338561</td>\n",
       "      <td>1.715868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black mrh blade lower tip cap screws worn. car...</td>\n",
       "      <td>black mrh blade lower tip cap screws removed ...</td>\n",
       "      <td>removed and replaced black mrh blade lower tip...</td>\n",
       "      <td>1.156229</td>\n",
       "      <td>1.715868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue mrb damper leaking out of limits.        ...</td>\n",
       "      <td>removed and replaced blue main rotor head dam...</td>\n",
       "      <td>removed and replaced blue main rotor damper ia...</td>\n",
       "      <td>1.621602</td>\n",
       "      <td>1.715868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>left hand nose landing gear tire worn. \\n\\n###...</td>\n",
       "      <td>replaced left nose landing gear tire iaw sss ...</td>\n",
       "      <td>replaced lh nlg tire iaw sss 3240. ataf apaf a...</td>\n",
       "      <td>1.236525</td>\n",
       "      <td>1.715868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scir change:  16pmgg9.  yellow blade tip cap s...</td>\n",
       "      <td>removed and replaced yellow bladetip cap scre...</td>\n",
       "      <td>removed and replased all tip cap screws iaw 15...</td>\n",
       "      <td>2.087995</td>\n",
       "      <td>1.715868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Issue  \\\n",
       "0  mrh aft scissors has side to side play        ...   \n",
       "1  black mrh blade lower tip cap screws worn. car...   \n",
       "2  blue mrb damper leaking out of limits.        ...   \n",
       "3  left hand nose landing gear tire worn. \\n\\n###...   \n",
       "4  scir change:  16pmgg9.  yellow blade tip cap s...   \n",
       "\n",
       "                                     Actual_Solution  \\\n",
       "0   removed, inspected, and reshimmed aft scissor...   \n",
       "1   black mrh blade lower tip cap screws removed ...   \n",
       "2   removed and replaced blue main rotor head dam...   \n",
       "3   replaced left nose landing gear tire iaw sss ...   \n",
       "4   removed and replaced yellow bladetip cap scre...   \n",
       "\n",
       "                                       Pred_Solution  Response_PPL  Total_PPL  \n",
       "0  inspected mrh aft scissor iaw 150-300. play is...      1.338561   1.715868  \n",
       "1  removed and replaced black mrh blade lower tip...      1.156229   1.715868  \n",
       "2  removed and replaced blue main rotor damper ia...      1.621602   1.715868  \n",
       "3  replaced lh nlg tire iaw sss 3240. ataf apaf a...      1.236525   1.715868  \n",
       "4  removed and replased all tip cap screws iaw 15...      2.087995   1.715868  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Data/output_test_curie_full_ppl.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "acro_dict = {\n",
    "    \"mrh\": \"main rotor head\",\n",
    "    \"nlg\": \"nose landing gear\",\n",
    "    \"tr\": \"tail rotor\",\n",
    "    \"aff\": \"area fod free\",\n",
    "    \"hyd\": \"hydraulic\",\n",
    "    \"oz\": \"ounces\",\n",
    "    \"tr\": \"tail rotor \",\n",
    "    \"r&r\": \"removed and replaced\",\n",
    "    \"mlg\": \"main landing gear\",\n",
    "    \"lh\": \"left hand\",\n",
    "    \"rh\": \"right hand\",\n",
    "    \"quad\": \"quadrant\",\n",
    "    \"tq\": \"torque\",\n",
    "    \"lgcu\": \"landing gear control unit\",\n",
    "    \"150-300\": \"num_main\",\n",
    "    \"3240\": \"main_num\",\n",
    "}\n",
    "\n",
    "rev_dict = {\"num_main\":\"150-300\",\n",
    "           \"main_num\": \"3240\"}\n",
    "\n",
    "def replace_acronym(text):\n",
    "    for acr, full in acro_dict.items():\n",
    "        text = text.replace(acr.lower(), full)\n",
    "    return text\n",
    "\n",
    "def remove_eos(text, eos_token=\" <EOS>\"):\n",
    "    t2 = text.replace(eos_token, \"\")\n",
    "    return t2\n",
    "\n",
    "def replace_num_grp(text):\n",
    "    t3 = re.sub('[\\d]+', '#num', text)\n",
    "    return t3\n",
    "\n",
    "def revert_val(text1):\n",
    "    for acr, full in rev_dict.items():\n",
    "        text1 = text1.replace(acr, full)\n",
    "    return text1\n",
    "\n",
    "def process_data(text):\n",
    "    \"\"\"\n",
    "    Processes data: includes conversion from short form to full form and replacing numbers except a few top occuring ones\n",
    "    \"\"\"\n",
    "    t1 = replace_acronym(text)\n",
    "    t2 = remove_eos(t1)\n",
    "    t3 = replace_num_grp(t2)\n",
    "    t4 = revert_val(t3)\n",
    "    return t4\n",
    "\n",
    "def get_gpt2_tokenized_text(text, tokenizer):\n",
    "    \"\"\"\n",
    "    Tokenize and create a list of tokenized words as per GPT-2 tokenizer \n",
    "    \"\"\"\n",
    "    tokens1   = tokenizer(text)['input_ids']\n",
    "    list_toks = [tokenizer.decode(x).strip().lower() for x in tokens1]\n",
    "    return list_toks\n",
    "\n",
    "def load_support_spacy():\n",
    "    \"Loads all supporting requirements for punctuations, stopwords, stemmer\"\n",
    "    \n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    # Create our list of punchuation marks\n",
    "    punctuations = string.punctuation\n",
    "     # Create our list of stop words\n",
    "    stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "    # Load Porter\n",
    "    porterStemmer = PorterStemmer()\n",
    "    \n",
    "    return nlp, punctuations, stop_words, porterStemmer\n",
    "\n",
    "def spacy_tokenizer(sent, nlp, punctuations, stop_words, porterStemmer, stem = False):\n",
    "    \"\"\"This function will accept a sentence as input and process the sentence into tokens, performing stemming, \n",
    "    lowercasing, removing stop words and punctuations.\"\"\"\n",
    "    \n",
    "    doc = nlp(sent)\n",
    "    mytokens = [token.text.lower() for token in doc if token.text not in stop_words and token.text not in punctuations]    \n",
    "    if stem:\n",
    "        # Perform stemming to get root words \n",
    "        mytokens = [porterStemmer.stem(word) for word in mytokens]\n",
    "\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Upd_Actual_Solution'] = data['Actual_Solution'].apply(lambda x: process_data(x))\n",
    "data['Upd_Pred_Solution']   = data['Pred_Solution'].apply(lambda x: process_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3320/3320 [00:24<00:00, 135.40it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3320/3320 [00:25<00:00, 132.31it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp, punctuations, stop_words, porterStemmer = load_support_spacy()\n",
    "pred_tokens = [spacy_tokenizer(sent, nlp, punctuations, stop_words, porterStemmer, stem=True) for sent in tqdm(data['Upd_Pred_Solution'])]\n",
    "act_tokens  = [[spacy_tokenizer(sent, nlp, punctuations, stop_words, porterStemmer, stem=True)] for sent in tqdm(data['Upd_Actual_Solution'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.2905331425479142,\n",
       " 'precisions': [0.593419740777667,\n",
       "  0.3600687696217671,\n",
       "  0.2455088878401762,\n",
       "  0.17156846473029044],\n",
       " 'brevity_penalty': 0.9432626748188677,\n",
       " 'length_ratio': 0.9448130155697003,\n",
       " 'translation_length': 70210,\n",
       " 'reference_length': 74311}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_list = list_metrics()\n",
    "bleu         = load_metric('bleu')\n",
    "bleu_score   = bleu.compute(predictions=pred_tokens, references=act_tokens,max_order=4)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.3531052737941756,\n",
       " 'precisions': [0.593419740777667, 0.3600687696217671, 0.2455088878401762],\n",
       " 'brevity_penalty': 0.9432626748188677,\n",
       " 'length_ratio': 0.9448130155697003,\n",
       " 'translation_length': 70210,\n",
       " 'reference_length': 74311}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_list = list_metrics()\n",
    "bleu         = load_metric('bleu')\n",
    "bleu_score   = bleu.compute(predictions=pred_tokens, references=act_tokens,max_order=3)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.4360199609948481,\n",
       " 'precisions': [0.593419740777667, 0.3600687696217671],\n",
       " 'brevity_penalty': 0.9432626748188677,\n",
       " 'length_ratio': 0.9448130155697003,\n",
       " 'translation_length': 70210,\n",
       " 'reference_length': 74311}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_list = list_metrics()\n",
    "bleu         = load_metric('bleu')\n",
    "bleu_score   = bleu.compute(predictions=pred_tokens, references=act_tokens,max_order=2)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.5597506919762613,\n",
       " 'precisions': [0.593419740777667],\n",
       " 'brevity_penalty': 0.9432626748188677,\n",
       " 'length_ratio': 0.9448130155697003,\n",
       " 'translation_length': 70210,\n",
       " 'reference_length': 74311}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_list = list_metrics()\n",
    "bleu         = load_metric('bleu')\n",
    "bleu_score   = bleu.compute(predictions=pred_tokens, references=act_tokens,max_order=1)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 23.642324852109972,\n",
       " 'counts': [50018, 28500, 18700, 12743],\n",
       " 'totals': [95625, 92305, 88985, 85665],\n",
       " 'precisions': [52.30640522875817,\n",
       "  30.87590054709929,\n",
       "  21.01477777153453,\n",
       "  14.87538668067472],\n",
       " 'bp': 0.8869482621085094,\n",
       " 'sys_len': 95625,\n",
       " 'ref_len': 107097}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbleu         = load_metric('sacrebleu')\n",
    "sbleu_score   = sbleu.compute(predictions=data['Pred_Solution'].tolist(), references=[[x] for x in data['Actual_Solution']])\n",
    "sbleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.5941932345005622, recall=0.5832325193353943, fmeasure=0.5697916436086047), mid=Score(precision=0.6020652308667536, recall=0.5913538654647492, fmeasure=0.5773395798425655), high=Score(precision=0.6102303735716907, recall=0.5991253772969031, fmeasure=0.5841931021992998)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.3923231297694795, recall=0.38449693123011286, fmeasure=0.3762251449404273), mid=Score(precision=0.400561292696072, recall=0.3931981345004616, fmeasure=0.384381882447152), high=Score(precision=0.40909435282565887, recall=0.4011351538239484, fmeasure=0.3921502186977758)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.5294247524074076, recall=0.5204112435605912, fmeasure=0.5083175344316421), mid=Score(precision=0.5377844997465213, recall=0.5285399064603791, fmeasure=0.515955154695161), high=Score(precision=0.5457391139895541, recall=0.5363425625393664, fmeasure=0.523528685053943)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.5298460793380844, recall=0.5208545516993917, fmeasure=0.5084065975207679), mid=Score(precision=0.5377864123359397, recall=0.5284226250303079, fmeasure=0.5159688936316476), high=Score(precision=0.5458722811534152, recall=0.5366528659219568, fmeasure=0.5234385835573367))}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge   = load_metric('rouge')\n",
    "rouge   = rouge.compute(predictions=data['Upd_Pred_Solution'].tolist(), references=[[x] for x in data['Upd_Actual_Solution']])\n",
    "rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE MEAN RESPONSE PERPLEXITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9041122266641177"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Response_PPL'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METRICS FOR WORD TOKENIZER ON UNPROCESSED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3320/3320 [00:22<00:00, 148.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3320/3320 [00:22<00:00, 145.40it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp, punctuations, stop_words, porterStemmer = load_support_spacy()\n",
    "pred_tokens = [spacy_tokenizer(sent, nlp, punctuations, stop_words, porterStemmer, stem=False) for sent in tqdm(data['Pred_Solution'])]\n",
    "act_tokens  = [[spacy_tokenizer(sent, nlp, punctuations, stop_words, porterStemmer, stem=False)] for sent in tqdm(data['Actual_Solution'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.20517612194314272,\n",
       " 'precisions': [0.521076260206695,\n",
       "  0.2784420692061277,\n",
       "  0.1719006327630654,\n",
       "  0.11218050976638662],\n",
       " 'brevity_penalty': 0.8921113417914803,\n",
       " 'length_ratio': 0.8975336686678566,\n",
       " 'translation_length': 66378,\n",
       " 'reference_length': 73956}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_list = list_metrics()\n",
    "bleu         = load_metric('bleu')\n",
    "bleu_score   = bleu.compute(predictions=pred_tokens, references=act_tokens,max_order=4)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.26064952184373114,\n",
       " 'precisions': [0.521076260206695, 0.2784420692061277, 0.1719006327630654],\n",
       " 'brevity_penalty': 0.8921113417914803,\n",
       " 'length_ratio': 0.8975336686678566,\n",
       " 'translation_length': 66378,\n",
       " 'reference_length': 73956}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_list = list_metrics()\n",
    "bleu         = load_metric('bleu')\n",
    "bleu_score   = bleu.compute(predictions=pred_tokens, references=act_tokens,max_order=3)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.3398107633203335,\n",
       " 'precisions': [0.521076260206695, 0.2784420692061277],\n",
       " 'brevity_penalty': 0.8921113417914803,\n",
       " 'length_ratio': 0.8975336686678566,\n",
       " 'translation_length': 66378,\n",
       " 'reference_length': 73956}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_list = list_metrics()\n",
    "bleu         = load_metric('bleu')\n",
    "bleu_score   = bleu.compute(predictions=pred_tokens, references=act_tokens,max_order=2)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.46485804166868117,\n",
       " 'precisions': [0.521076260206695],\n",
       " 'brevity_penalty': 0.8921113417914803,\n",
       " 'length_ratio': 0.8975336686678566,\n",
       " 'translation_length': 66378,\n",
       " 'reference_length': 73956}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_list = list_metrics()\n",
    "bleu         = load_metric('bleu')\n",
    "bleu_score   = bleu.compute(predictions=pred_tokens, references=act_tokens,max_order=1)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION FOR N-SHOT SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>actual_completion</th>\n",
       "      <th>finetune_completion</th>\n",
       "      <th>nshot_completion_curie</th>\n",
       "      <th>nshot_completion_davinci</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mrh aft scissors has side to side play        ...</td>\n",
       "      <td>removed, inspected, and reshimmed aft scissor...</td>\n",
       "      <td>inspected mrh aft scissor iaw 150-300. play is...</td>\n",
       "      <td>inspeted mrh aft scissors side to side play ia...</td>\n",
       "      <td>replaced aft scissors iaw 150-300. checks goo...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black mrh blade lower tip cap screws worn. car...</td>\n",
       "      <td>black mrh blade lower tip cap screws removed ...</td>\n",
       "      <td>removed and replaced black mrh blade lower tip...</td>\n",
       "      <td>removed and replaced black mrh blade lower tip...</td>\n",
       "      <td>removed and replaced black blade lower tip cap...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue mrb damper leaking out of limits.        ...</td>\n",
       "      <td>removed and replaced blue main rotor head dam...</td>\n",
       "      <td>removed and replaced blue main rotor damper ia...</td>\n",
       "      <td>inspected and replaced blue mrb damper iaw 150...</td>\n",
       "      <td>removed and replaced blue mrb damper iaw 150-3...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>left hand nose landing gear tire worn. \\n\\n###...</td>\n",
       "      <td>replaced left nose landing gear tire iaw sss ...</td>\n",
       "      <td>replaced lh nlg tire iaw sss 3240. ataf apaf a...</td>\n",
       "      <td>iaw s/n 2120 removed and replaced left hand no...</td>\n",
       "      <td>removed and replaced left hand nose landing ge...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scir change:  16pmgg9.  yellow blade tip cap s...</td>\n",
       "      <td>removed and replaced yellow bladetip cap scre...</td>\n",
       "      <td>removed and replased all tip cap screws iaw 15...</td>\n",
       "      <td>replaced screws iaw a1-h60ra-140-300. all chec...</td>\n",
       "      <td>replaced yellow blade tip cap screws iaw a1-h6...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  mrh aft scissors has side to side play        ...   \n",
       "1  black mrh blade lower tip cap screws worn. car...   \n",
       "2  blue mrb damper leaking out of limits.        ...   \n",
       "3  left hand nose landing gear tire worn. \\n\\n###...   \n",
       "4  scir change:  16pmgg9.  yellow blade tip cap s...   \n",
       "\n",
       "                                   actual_completion  \\\n",
       "0   removed, inspected, and reshimmed aft scissor...   \n",
       "1   black mrh blade lower tip cap screws removed ...   \n",
       "2   removed and replaced blue main rotor head dam...   \n",
       "3   replaced left nose landing gear tire iaw sss ...   \n",
       "4   removed and replaced yellow bladetip cap scre...   \n",
       "\n",
       "                                 finetune_completion  \\\n",
       "0  inspected mrh aft scissor iaw 150-300. play is...   \n",
       "1  removed and replaced black mrh blade lower tip...   \n",
       "2  removed and replaced blue main rotor damper ia...   \n",
       "3  replaced lh nlg tire iaw sss 3240. ataf apaf a...   \n",
       "4  removed and replased all tip cap screws iaw 15...   \n",
       "\n",
       "                              nshot_completion_curie  \\\n",
       "0  inspeted mrh aft scissors side to side play ia...   \n",
       "1  removed and replaced black mrh blade lower tip...   \n",
       "2  inspected and replaced blue mrb damper iaw 150...   \n",
       "3  iaw s/n 2120 removed and replaced left hand no...   \n",
       "4  replaced screws iaw a1-h60ra-140-300. all chec...   \n",
       "\n",
       "                            nshot_completion_davinci Comment  \n",
       "0   replaced aft scissors iaw 150-300. checks goo...    None  \n",
       "1  removed and replaced black blade lower tip cap...    None  \n",
       "2  removed and replaced blue mrb damper iaw 150-3...    None  \n",
       "3  removed and replaced left hand nose landing ge...    None  \n",
       "4  replaced yellow blade tip cap screws iaw a1-h6...    None  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsdata = pd.read_csv(\"./Data/API_Comparisons.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsdata['Upd_Finetune']      = nsdata['finetune_completion'].apply(lambda x: process_data(x))\n",
    "nsdata['Upd_NShot_Curie']   = nsdata['nshot_completion_curie'].apply(lambda x: process_data(x))\n",
    "nsdata['Upd_NShot_Davinci'] = nsdata['nshot_completion_davinci'].apply(lambda x: process_data(x))\n",
    "nsdata['Upd_Actual']        = nsdata['actual_completion'].apply(lambda x: process_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.5596612734752757, recall=0.48957065261166266, fmeasure=0.5042537855440952), mid=Score(precision=0.6538003607794429, recall=0.6021880074274288, fmeasure=0.6023432561721545), high=Score(precision=0.7502726022394897, recall=0.7113032944473935, fmeasure=0.7036463174742328)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.35353197037137374, recall=0.31189652844713506, fmeasure=0.3182310410510946), mid=Score(precision=0.4586681247628679, recall=0.4190763039206067, fmeasure=0.42374923010905213), high=Score(precision=0.5786169715846395, recall=0.552809710791453, fmeasure=0.549162418690499)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.47035174834187093, recall=0.4148356490598334, fmeasure=0.42916171557913335), mid=Score(precision=0.5782386734305771, recall=0.523951477957332, fmeasure=0.5332462851019608), high=Score(precision=0.6811627791850565, recall=0.6533938790615401, fmeasure=0.648514029849493)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.47046535909408144, recall=0.4066650767901539, fmeasure=0.4211618652351871), mid=Score(precision=0.5789278642181119, recall=0.5315677788565916, fmeasure=0.5350856263141803), high=Score(precision=0.6873576613772148, recall=0.6518605288728571, fmeasure=0.6466980481231727))}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge   = load_metric('rouge')\n",
    "rouge   = rouge.compute(predictions=nsdata['Upd_Finetune'].tolist(), references=[[x] for x in nsdata['Upd_Actual']])\n",
    "rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.3727761920095415, recall=0.33187928220407736, fmeasure=0.3428473353168135), mid=Score(precision=0.45302617484069096, recall=0.4149446177937377, fmeasure=0.40525603857513415), high=Score(precision=0.5266320113578178, recall=0.49914848082086083, fmeasure=0.45865839804286856)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.19672337242401802, recall=0.17291969498149773, fmeasure=0.17850236802854452), mid=Score(precision=0.2504350316192491, recall=0.22823338350723493, fmeasure=0.22224153617693249), high=Score(precision=0.311061475451906, recall=0.29316945208894973, fmeasure=0.2711426933103656)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.3458436714237952, recall=0.30343301192714517, fmeasure=0.3101075605139638), mid=Score(precision=0.41222663063875525, recall=0.3796201733190164, fmeasure=0.3701150436567302), high=Score(precision=0.4819075577200576, recall=0.465647164931456, fmeasure=0.4238865920302943)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.3433292589151878, recall=0.2911822605817612, fmeasure=0.3027666052159136), mid=Score(precision=0.41210779981358403, recall=0.3800073473661968, fmeasure=0.37107189036131627), high=Score(precision=0.473480864565542, recall=0.4718836920374006, fmeasure=0.42550553326077034))}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge   = load_metric('rouge')\n",
    "rouge   = rouge.compute(predictions=nsdata['Upd_NShot_Curie'].tolist(), references=[[x] for x in nsdata['Upd_Actual']])\n",
    "rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.3317821012544803, recall=0.24998039772727274, fmeasure=0.2793258171764496), mid=Score(precision=0.4507794868530163, recall=0.3618035019688044, fmeasure=0.38785760025205906), high=Score(precision=0.5466599818455842, recall=0.4780296548658058, fmeasure=0.4832542712371364)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.1719538665924215, recall=0.1366530350861225, fmeasure=0.1499098816953766), mid=Score(precision=0.2586128257541046, recall=0.21494735301892237, fmeasure=0.22664884973796823), high=Score(precision=0.34854815477972434, recall=0.29945255183221803, fmeasure=0.310942182768551)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.3006985047092376, recall=0.22776132986625844, fmeasure=0.2530169168284688), mid=Score(precision=0.41258742351365696, recall=0.33315649844513606, fmeasure=0.3561021864691335), high=Score(precision=0.5162586816514712, recall=0.4425359887049226, fmeasure=0.4578308279015947)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.30613448671821536, recall=0.22809461835334477, fmeasure=0.2573639580244085), mid=Score(precision=0.4169224482032831, recall=0.33427495543672014, fmeasure=0.35938059556796287), high=Score(precision=0.5107945725342545, recall=0.43479663375839833, fmeasure=0.4516550710057049))}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge   = load_metric('rouge')\n",
    "rouge   = rouge.compute(predictions=nsdata['Upd_NShot_Davinci'].tolist(), references=[[x] for x in nsdata['Upd_Actual']])\n",
    "rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 124.19it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 125.76it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 137.89it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 169.48it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp, punctuations, stop_words, porterStemmer = load_support_spacy()\n",
    "ftune_tokens = [spacy_tokenizer(sent, nlp, punctuations, stop_words, porterStemmer, stem=False) for sent in tqdm(nsdata['Upd_Finetune'])]\n",
    "act_tokens  = [[spacy_tokenizer(sent, nlp, punctuations, stop_words, porterStemmer, stem=False)] for sent in tqdm(nsdata['Upd_Actual'])]\n",
    "curie_tokens = [spacy_tokenizer(sent, nlp, punctuations, stop_words, porterStemmer, stem=False) for sent in tqdm(nsdata['Upd_NShot_Curie'])]\n",
    "davinci_tokens = [spacy_tokenizer(sent, nlp, punctuations, stop_words, porterStemmer, stem=False) for sent in tqdm(nsdata['Upd_NShot_Davinci'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu Scores for 20 instance from 1 to 4 gram for Finetuned model: \n",
      "[0.4976118507175784, 0.4024628993333813, 0.3280804514054867, 0.27252460116453414]\n",
      "Bleu Scores for 20 instance model from 1 to 4 gram for Curie model: \n",
      "[0.32772594547320916, 0.24616958147111095, 0.18751735954917328, 0.143130473864383]\n",
      "Bleu Scores for 20 instance model from 1 to 4 gram for Davinci model: \n",
      "[0.2504854584234485, 0.18523252387068123, 0.14253999618930616, 0.1098713100240581]\n"
     ]
    }
   ],
   "source": [
    "metrics_list = list_metrics()\n",
    "bleu         = load_metric('bleu')\n",
    "bleu_ngram_ft    = []\n",
    "bleu_ngram_curie = []\n",
    "bleu_ngram_dvnci = []\n",
    "for i in range(1,5):\n",
    "    bleu_ngram_ft.append(bleu.compute(predictions=ftune_tokens, references=act_tokens,max_order=i)['bleu'])\n",
    "    bleu_ngram_curie.append(bleu.compute(predictions=curie_tokens, references=act_tokens,max_order=i)['bleu'])\n",
    "    bleu_ngram_dvnci.append(bleu.compute(predictions=davinci_tokens, references=act_tokens,max_order=i)['bleu'])\n",
    "print(\"Bleu Scores for 20 instance from 1 to 4 gram for Finetuned model: \")\n",
    "print(bleu_ngram_ft)\n",
    "print(\"Bleu Scores for 20 instance model from 1 to 4 gram for Curie model: \")\n",
    "print(bleu_ngram_curie)\n",
    "print(\"Bleu Scores for 20 instance model from 1 to 4 gram for Davinci model: \")\n",
    "print(bleu_ngram_dvnci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION ON RAW DATASET PREDICTION FOR GPT-2 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer   = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "pred_tokens = [get_gpt2_tokenized_text(i[:-1], tokenizer) for i in tqdm(data['Pred_Solution'])]\n",
    "act_tokens  = [[get_gpt2_tokenized_text(i[:-1], tokenizer)] for i in tqdm(data['Actual_Solution'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLEU SCORE COMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_list = list_metrics()\n",
    "bleu         = load_metric('bleu')\n",
    "bleu_score   = bleu.compute(predictions=pred_tokens, references=act_tokens,max_order=4)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = list_metrics()\n",
    "bleu         = load_metric('bleu')\n",
    "bleu_score   = bleu.compute(predictions=pred_tokens, references=act_tokens,max_order=3)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = list_metrics()\n",
    "bleu         = load_metric('bleu')\n",
    "bleu_score   = bleu.compute(predictions=pred_tokens, references=act_tokens,max_order=2)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = list_metrics()\n",
    "bleu         = load_metric('bleu')\n",
    "bleu_score   = bleu.compute(predictions=pred_tokens, references=act_tokens,max_order=1)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SACREBLEU SCORE COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbleu         = load_metric('sacrebleu')\n",
    "sbleu_score   = sbleu.compute(predictions=data['Pred_Solution'].tolist(), references=[[x] for x in data['Actual_Solution']])\n",
    "sbleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbleu         = load_metric('sacrebleu')\n",
    "sbleu_score   = sbleu.compute(predictions=pred_tokens, references=act_tokens)\n",
    "sbleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUGE SCORE EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge   = load_metric('rouge')\n",
    "rouge   = rouge.compute(predictions=data['Pred_Solution'].tolist(), references=[[x] for x in data['Actual_Solution']])\n",
    "rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLEURT METRIC EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bleurt   = load_metric('bleurt')\n",
    "# bleurt   = bleurt.compute(predictions=data['Pred_Solution'].tolist(), references=[[x] for x in data['Actual_Solution']])\n",
    "# bleurt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install git+https://github.com/google-research/bleurt.git\n",
    "# !pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TFIDF Scores for each word-token\n",
    "corpus     = data['Actual_Solution'].tolist()\n",
    "vectorizer = TfidfVectorizer(max_df=5000)\n",
    "X          = vectorizer.fit_transform(corpus)\n",
    "map_tfidf  = dict(zip(vectorizer.get_feature_names(), X.toarray()[0]))\n",
    "\n",
    "key_li = []\n",
    "val_li = []\n",
    "for k,v in map_tfidf.items():\n",
    "    if v>= 0.01:\n",
    "        key_li.append(k)\n",
    "        val_li.append(v)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_li = [nltk.word_tokenize(x) for x in data['Actual_Solution'].tolist()]\n",
    "tokenized = [i for sub in tokenized_li for i in sub]\n",
    "sorted(Counter(tokenized).items(), key=lambda x: x[1], reverse= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION ON PROCESSED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer   = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "pred_tokens = [get_gpt2_tokenized_text(i[:-1], tokenizer) for i in tqdm(data['Upd_Pred_Solution'])]\n",
    "act_tokens  = [[get_gpt2_tokenized_text(i[:-1], tokenizer)] for i in tqdm(data['Upd_Actual_Solution'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = list_metrics()\n",
    "bleu         = load_metric('bleu')\n",
    "bleu_score   = bleu.compute(predictions=pred_tokens, references=act_tokens,max_order=4)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = list_metrics()\n",
    "bleu         = load_metric('bleu')\n",
    "bleu_score   = bleu.compute(predictions=pred_tokens, references=act_tokens,max_order=3)\n",
    "bleu_score      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = list_metrics()\n",
    "bleu         = load_metric('bleu')\n",
    "bleu_score   = bleu.compute(predictions=pred_tokens, references=act_tokens,max_order=2)\n",
    "bleu_score      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = list_metrics()\n",
    "bleu         = load_metric('bleu')\n",
    "bleu_score   = bleu.compute(predictions=pred_tokens, references=act_tokens,max_order=1)\n",
    "bleu_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbleu         = load_metric('sacrebleu')\n",
    "sbleu_score   = sbleu.compute(predictions=data['Upd_Pred_Solution'].tolist(), references=[[x] for x in data['Upd_Actual_Solution']])\n",
    "sbleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbleu         = load_metric('sacrebleu')\n",
    "sbleu_score   = sbleu.compute(predictions=pred_tokens, references=act_tokens)\n",
    "sbleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge   = load_metric('rouge')\n",
    "rouge   = rouge.compute(predictions=data['Upd_Pred_Solution'].tolist(), references=[[x] for x in data['Upd_Actual_Solution']])\n",
    "rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION USING WORD TOKENS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk\n",
    "# !pip install spacy==2.3.5\n",
    "# !pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n",
    "# ! pip install pyresparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall spacy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
